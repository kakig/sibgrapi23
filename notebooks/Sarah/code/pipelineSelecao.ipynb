{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enchant\n",
    "from PIL import Image, ImageEnhance\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "import cv2\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imgProcessor.measure.sharpness import parameters\n",
    "import imutils\n",
    "from scipy.signal import convolve2d\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracyByLevenshteinDistance(textOCR,label):\n",
    "    #tira espaços, tab e \\n\n",
    "    text = re.sub(r\"[\\n\\t\\s]*\", \"\", textOCR)\n",
    "    labelText = re.sub(r\"[\\n\\t\\s]*\", \"\", label)\n",
    "    \n",
    "    #calcula a distancia de levenshtein entre os textos\n",
    "    levDistance = enchant.utils.levenshtein(text, labelText)\n",
    "    \n",
    "    #calcula a acurácia fazendo accuracy = n-erros/n\n",
    "    accuracy = (len(labelText)-levDistance) / len(labelText)\n",
    "    return accuracy\n",
    "\n",
    "def blurLevel(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "\n",
    "def biggest_contour(contours):\n",
    "        biggest = np.array([])\n",
    "        max_area = 0\n",
    "        for i in contours:\n",
    "            area = cv2.contourArea(i)\n",
    "            if area > 58000:\n",
    "                peri = cv2.arcLength(i, True)\n",
    "                approx = cv2.approxPolyDP(i, 0.015 * peri, True)\n",
    "                if area > max_area and len(approx) == 4:\n",
    "                    biggest = approx\n",
    "                    max_area = area\n",
    "        return biggest\n",
    " \n",
    "\n",
    "def order_points(pts):\n",
    "        rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "        s = np.sum(pts,axis = 1)\n",
    "\n",
    "        rect[0] = pts[np.argmin(s)]\n",
    "        rect[2] = pts[np.argmax(s)]\n",
    "        \n",
    "        diff = np.diff(pts, axis = 1)\n",
    "        rect[3] = pts[np.argmin(diff)]\n",
    "        rect[1] = pts[np.argmax(diff)]\n",
    "     \n",
    "        # return the ordered coordinates\n",
    "        return rect\n",
    "       \n",
    "def getAngle(img):\n",
    "    image = imutils.resize(img, height = 500)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    gray = cv2.bilateralFilter(gray, 20, 30, 30)\n",
    "    edged = cv2.Canny(gray, 50, 150)\n",
    "    \n",
    "  \n",
    "    cnts = None\n",
    "    cnts, hierarchy  = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:10]\n",
    "\n",
    "    \n",
    "    screenCnt = None\n",
    "    screenCnt = biggest_contour(cnts)\n",
    "    \n",
    "    if(len(screenCnt)==0 ):\n",
    "        edged = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,13,0.5)\n",
    "        cnts = None\n",
    "        cnts, hierarchy  = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:10]\n",
    "        \n",
    "        screenCnt = None\n",
    "        screenCnt = biggest_contour(cnts)\n",
    "\n",
    "    if(len(screenCnt) >0 ):\n",
    "        cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 1)\n",
    "        screenCnt = order_points(screenCnt[:,0,:])\n",
    "        angle = cv2.minAreaRect(screenCnt)[-1]\n",
    "        angle = 90 - angle if (angle>45) else angle        \n",
    "        \n",
    "        return angle\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def estimate_noise(I):\n",
    "    \n",
    "    I = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)\n",
    "    Image  = cv2.Sobel(src=I, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=5) #\n",
    "    \n",
    "    H, W = Image.shape\n",
    "\n",
    "    M = [[1, -2, 1],\n",
    "        [-2, 4, -2],\n",
    "        [1, -2, 1]]\n",
    "\n",
    "    sigma = np.sum(np.sum(np.absolute(convolve2d(Image, M))))\n",
    "\n",
    "    sigma = sigma * (math.sqrt(math.pi/2) * (1 /  (6 * (W-2) * (H-2))))\n",
    "\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyAll = np.array([])\n",
    "accuracyGood = np.array([])\n",
    "accuracyMedium = np.array([])\n",
    "accuracyBad = np.array([])\n",
    "\n",
    "indexGood = np.array([])\n",
    "indexMedium = np.array([])\n",
    "indexBad = np.array([])\n",
    "\n",
    "for i in range(0,200):\n",
    "    img = np.array([])\n",
    "    img = cv2.imread('./images/1'+str(i).zfill(3) +'-receipt.jpg')\n",
    "    if (i == 25 or i == 34 or i == 41 or i == 45 or i == 63 or i == 109 or i == 137 or i == 169 or i == 194 or i == 192): continue\n",
    "    \n",
    "    label = open('./images/1'+str(i).zfill(3)+'-receipt.txt', 'r') \n",
    "    labelText = label.read()\n",
    "    \n",
    "    imgBlurLevel = blurLevel(img)\n",
    "    noiseLevel = estimate_noise(img)\n",
    "    imgAngle = getAngle(img)\n",
    "    \n",
    "    text =''\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    accuracy = accuracyByLevenshteinDistance(text,labelText)\n",
    "    accuracyAll = np.append(accuracyAll, accuracy)\n",
    "    \n",
    "    #boas - aceitaveis\n",
    "    if((imgBlurLevel >= 630 and imgBlurLevel <= 1150 and noiseLevel <= 13) or (imgBlurLevel > 1150 and imgBlurLevel <= 1310 and noiseLevel <= 20)):\n",
    "        if(imgAngle != None):\n",
    "            if(imgAngle <= 0.59514):\n",
    "                indexGood = np.append(indexGood,i)\n",
    "                accuracyGood = np.append(accuracyGood, accuracy)\n",
    "                \n",
    "        else:\n",
    "            indexGood = np.append(indexGood,i)\n",
    "            accuracyGood = np.append(accuracyGood, accuracy)\n",
    "    \n",
    "for i in range(0,200):\n",
    "    img = np.array([])\n",
    "    img = cv2.imread('./images/1'+str(i).zfill(3) +'-receipt.jpg')\n",
    "    if (i == 25 or i == 34 or i == 41 or i == 45 or i == 63 or i == 109 or i == 137 or i == 169 or i == 194 or i == 192): continue\n",
    "    if(len(indexGood[indexGood == i] ) != 0): continue\n",
    "    \n",
    "    label = open('./images/1'+str(i).zfill(3)+'-receipt.txt', 'r') \n",
    "    labelText = label.read()\n",
    "    \n",
    "    imgBlurLevel = blurLevel(img)\n",
    "    noiseLevel = estimate_noise(img)\n",
    "    imgAngle = getAngle(img)\n",
    "    \n",
    "    text =''\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    accuracy = accuracyByLevenshteinDistance(text,labelText)\n",
    "    accuracyAll = np.append(accuracyAll, accuracy)\n",
    "    \n",
    "    #a serem melhoradas\n",
    "    if((imgBlurLevel < 350 and noiseLevel < 12) or (imgBlurLevel > 650 and noiseLevel > 25 and noiseLevel < 35)):\n",
    "        if(imgAngle != None):\n",
    "            if(imgAngle < 3):\n",
    "                indexMedium = np.append(indexMedium,i)\n",
    "                accuracyMedium = np.append(accuracyMedium, accuracy)\n",
    "        else:\n",
    "            indexMedium = np.append(indexMedium,i)\n",
    "            accuracyMedium = np.append(accuracyMedium, accuracy)\n",
    "    else:\n",
    "        indexBad = np.append(indexBad,i)\n",
    "        accuracyBad = np.append(accuracyBad, accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5918376762112326\n",
      "0.7923624485144304\n",
      "0.5860999973063405\n",
      "0.5738828328573803\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accuracyAll))\n",
    "print(np.mean(accuracyGood))\n",
    "print(np.mean(accuracyMedium))\n",
    "print(np.mean(accuracyBad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"accuracy_1.csv\")\n",
    "df2 = pd.read_csv(\"accuracy_2.csv\")\n",
    "\n",
    "accuracyAfter = pd.concat([df1, df2])\n",
    "# print(accuracyAfter)\n",
    "\n",
    "accAfter = np.asarray(accuracyAfter['Accuracy'].to_list(), dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accMelhorar = np.array([])\n",
    "\n",
    "for i in range(0,len(indexMedium)):\n",
    "    name = '1' + str(int(indexMedium[i])).zfill(3)\n",
    "#     print(accuracyAfter['Image'].to_list())\n",
    "    if(int(name) not in accuracyAfter['Image'].to_list()): continue\n",
    "    acc = accuracyAfter['Accuracy'].where(accuracyAfter['Image'] == int(name)).dropna().to_list()[0]\n",
    "#     print(acc)\n",
    "    accMelhorar = np.append(accMelhorar, acc)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7412728191930857\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accMelhorar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3eb3386723f9a6fe095063f0492a6f1413a5cebdc23dea2c922e7b4594c402f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
